{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2U5rK0B-VA3C"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openslide import open_slide, __library_version__ as openslide_version\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpWLZsRoVcNi"
   },
   "outputs": [],
   "source": [
    "test_index = '110'\n",
    "slide_path = '../images/tumor_' + test_index + '.tif'\n",
    "tumor_mask_path = '../images/tumor_' + test_index + '_mask.tif'\n",
    "slide, tumor_mask = open_slide(slide_path), open_slide(tumor_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxLC8GTlV8SV"
   },
   "outputs": [],
   "source": [
    "# Read a region from the slide\n",
    "# Return a numpy RBG array\n",
    "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
    "    im = slide.read_region((x,y), level, (width, height))\n",
    "    im = im.convert('RGB') # drop the alpha channel\n",
    "    if as_float:\n",
    "        im = np.asarray(im, dtype=np.float32)\n",
    "    else:\n",
    "        im = np.asarray(im)\n",
    "    assert im.shape == (height, width, 3)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1556375139672,
     "user": {
      "displayName": "Ge Qu",
      "photoUrl": "https://lh5.googleusercontent.com/-iEH2Ac57Aww/AAAAAAAAAAI/AAAAAAAAAHs/8kCEK_iSPjc/s64/photo.jpg",
      "userId": "01568046772032294911"
     },
     "user_tz": 240
    },
    "id": "pekpwmA0WBBk",
    "outputId": "2d02bd29-3431-456c-cf46-3da95fdc33e0"
   },
   "outputs": [],
   "source": [
    "def get_center(slide):\n",
    "  coor = []\n",
    "  x_list = list(range((299//2)*8, (slide.level_dimensions[6][0] - 299//2)*8 , 128))\n",
    "  y_list = list(range((299//2)*8, (slide.level_dimensions[6][1] - 299//2)*8 , 128))\n",
    "  for x in x_list:\n",
    "    for y in y_list:\n",
    "      coor.append((x,y))\n",
    "  return coor\n",
    "#coor[i][0],coor[i][1]:x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6x4qBDn5leeN"
   },
   "outputs": [],
   "source": [
    "#extract patches for exact coors\n",
    "def extractpatches(image,x,y,level_num):\n",
    "  scale = 2**(level_num - 3)\n",
    "  scale2 = 2**level_num\n",
    "  region = read_slide(image, (x//scale - 299//2)*scale2, (y//scale - 299//2)*scale2, level = level_num, width=299, height=299)\n",
    "  return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3zoahvMlfsk"
   },
   "outputs": [],
   "source": [
    "def preparetestdata(image,coor_list,level_list):\n",
    "  res = []\n",
    "  for coor in coor_list:\n",
    "      patch = []\n",
    "      for level in level_list:\n",
    "        area = extractpatches(image,coor[0],coor[1],level)\n",
    "        patch.append(area)\n",
    "      res.append(patch)\n",
    "  res = np.array(res)\n",
    "  return res #res: np (#, 4,299,299,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CL3RGZ6axw_4"
   },
   "outputs": [],
   "source": [
    "#[3,4,5,6]\n",
    "coor_list = get_center(slide)\n",
    "res = preparetestdata(slide,coor_list,[3,4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.nn import softmax, sigmoid\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16,VGG19,inception_v3, densenet, mobilenet,mobilenet_v2\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = InceptionV3(include_top=False, weights='imagenet')\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [tf.keras.Input(shape=(299,299,3)),tf.keras.Input(shape=(299,299,3)), \\\n",
    "          tf.keras.Input(shape=(299,299,3)),tf.keras.Input(shape=(299,299,3))]\n",
    "\n",
    "layer1_conv = conv_base(inputs[0])\n",
    "layer1_flatten = Flatten()(layer1_conv)\n",
    "layer1_dense1 = Dense(64,activation = 'relu')(layer1_flatten)\n",
    "#layer1_dense2 = Dense(32,activation = 'relu')(layer1_dense1)\n",
    "layer1 = Dropout(0.4)(layer1_dense1)\n",
    "\n",
    "layer2_conv = conv_base(inputs[1])\n",
    "layer2_flatten = Flatten()(layer2_conv)\n",
    "layer2_dense1 = Dense(64,activation = 'relu')(layer2_flatten)\n",
    "#layer2_dense2 = Dense(32,activation = 'relu')(layer2_dense1)\n",
    "layer2 = Dropout(0.4)(layer2_dense1)\n",
    "\n",
    "layer3_conv = conv_base(inputs[2])\n",
    "layer3_flatten = Flatten()(layer3_conv)\n",
    "layer3_dense1 = Dense(64,activation = 'relu')(layer3_flatten)\n",
    "#layer3_dense2 = Dense(32,activation = 'relu')(layer3_dense1)\n",
    "layer3 = Dropout(0.4)(layer3_dense1)\n",
    "\n",
    "layer4_conv = conv_base(inputs[3])\n",
    "layer4_flatten = Flatten()(layer4_conv)\n",
    "layer4_dense1 = Dense(64,activation = 'relu')(layer4_flatten)\n",
    "#layer4_dense2 = Dense(32,activation = 'relu')(layer4_dense1)\n",
    "layer4 = Dropout(0.4)(layer4_dense1)\n",
    "\n",
    "merged_input = tf.concat([layer1,layer2,layer3,layer4],axis = 1)\n",
    "output = tf.keras.layers.Dense(1,'sigmoid')(merged_input)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.RMSprop(lr=0.05, rho=0.9, epsilon=1.0, decay=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer, loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../models/model_except110091110.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            multiple             21802784    input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 131072)       0           inception_v3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 131072)       0           inception_v3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 131072)       0           inception_v3[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 131072)       0           inception_v3[4][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8388672     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8388672     flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           8388672     flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8388672     flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_1 (TensorFlowOpLayer)    [(None, 256)]        0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            257         concat_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 55,357,729\n",
      "Trainable params: 33,554,945\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- current tumor: 0\n",
      "100 -- current tumor: 0\n",
      "200 -- current tumor: 1\n",
      "300 -- current tumor: 9\n",
      "400 -- current tumor: 35\n"
     ]
    }
   ],
   "source": [
    "final_coor = []\n",
    "cnt = 0\n",
    "for i,coor in enumerate(coor_list):\n",
    "    data =[res[[i],0,:,:,:]/255,res[[i],1,:,:,:]/255, res[[i],2,:,:,:]/255,res[[i],3,:,:,:]/255]\n",
    "    predict_res = model.predict(x = data,batch_size=1, verbose=0, steps=None, callbacks=None)\n",
    "    final_res = 1 if predict_res[0] > 0.95 else 0\n",
    "    if final_res == 1:\n",
    "        final_coor.append(coor)\n",
    "    if cnt%100 == 0:\n",
    "        print(cnt, \"-- current tumor:\" , len(final_coor))\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_coor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_image = read_slide(slide, \n",
    "                         x=0, \n",
    "                         y=0, \n",
    "                         level=3, \n",
    "                         width=slide.level_dimensions[3][0], \n",
    "                         height=slide.level_dimensions[3][1])\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=100)\n",
    "plt.imshow(slide_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tumor = np.where(mask_image == 1)\n",
    "#coor = list(zip(tumor[0], tumor[1]))\n",
    "coor = final_coor\n",
    "image_size = (slide_image.shape[0], slide_image.shape[1])\n",
    "predict_mask  = np.zeros(image_size,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotpredict(size, image, coor):\n",
    "    # @ functuin: plot predicted tumor\n",
    "    # @ param: size: patche's size | image: blank image | coor: tumors' predicted coordinates\n",
    "    # @ return: predicted tumor mask\n",
    "    for (x, y) in coor:\n",
    "        left, right = y - size/2, y + size/2\n",
    "        top, bottem = x - size/2, x + size/2\n",
    "        left, right,top, bottem = int(left), int(right), int(top), int(bottem)\n",
    "        image[left:right , top:bottem] = 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mask = plotpredict(128, predict_mask , coor)\n",
    "\n",
    "# Example: read the entire mask at the same zoom level\n",
    "mask_image = read_slide(tumor_mask, \n",
    "                        x=0, \n",
    "                        y=0, \n",
    "                        level=3, \n",
    "                        width=slide.level_dimensions[3][0], \n",
    "                        height=slide.level_dimensions[3][1])\n",
    "\n",
    "# Note: the program provided by the dataset authors generates a mask with R,G,B channels.\n",
    "# The mask info we need is in the first channel only.\n",
    "# If you skip this step, the mask will be displayed as all black.\n",
    "mask_image = mask_image[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10), dpi=100)\n",
    "for ax, img, interp in zip(ax, [predict_mask, mask_image],  ['predict', 'ground_truth']):\n",
    "    ax.imshow(img,cmap ='gray')\n",
    "    ax.set_title(interp)\n",
    "    ax.grid(False)\n",
    "\n",
    "plt.show()\n",
    "path = '../results/' + str(test_index) + '/' + 'tumor_mask.png'\n",
    "fig.savefig(path, dpi=fig.dpi, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=plt.imread(path)\n",
    "plt.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot on Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 10), dpi=100)\n",
    "\n",
    "axes[0].imshow(slide_image)\n",
    "axes[0].imshow(predict_mask, cmap='jet', alpha=0.5) # Red regions contains cancer.\n",
    "axes[0].set_title('prediction')\n",
    "\n",
    "axes[1].imshow(slide_image)\n",
    "axes[1].imshow(mask_image, cmap='jet', alpha=0.5) # Red regions contains cancer.\n",
    "axes[1].set_title('ground_truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../results/' + str(test_index) + '/' + 'tumor.png'\n",
    "fig.savefig(path, dpi=fig.dpi, bbox_inches='tight')\n",
    "img=plt.imread(path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOU and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
    "confusion_matrix = ConfusionMatrix(mask_image.reshape(-1), predict_mask.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Binary confusion matrix:\\n%s\" % confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# cm = np.array([[confusion_matrix.TP, confusion_matrix.FN], [confusion_matrix.FP, confusion_matrix.TN]])\n",
    "# cm = cm/cm.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = sns.heatmap(cm, center=0, annot=True, cmap=\"YlGnBu\",  xticklabels=['Pred_True', 'Pred_False'], yticklabels=['Actual_True', 'Actual_False'])\n",
    "# fig.figure.savefig('cm.png', bbox_inches='tight')\n",
    "# # img=plt.imread('cm.png')\n",
    "# # plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU = confusion_matrix.TP / (confusion_matrix.TP + confusion_matrix.FN + confusion_matrix.FP)\n",
    "RECALL = confusion_matrix.TP / (confusion_matrix.TP + confusion_matrix.FN)\n",
    "ACCURACY = (confusion_matrix.TP + confusion_matrix.TN) / (confusion_matrix.TN + confusion_matrix.TP + confusion_matrix.FN + confusion_matrix.FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IOU:\" + str(IOU), '\\nRecall' + str(RECALL), \"\\nAccuracy: \" + str(ACCURACY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../results/' + str(test_index) + '/' + 'pixel_metric.txt'\n",
    "file = open(path,\"w\")\n",
    "file.write('IOU: ' + str(IOU)) \n",
    "file.write('\\nRECALL: ' + str(RECALL))\n",
    "file.write('\\nACCURACY: ' + str(ACCURACY))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10164"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "dp_predict.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
